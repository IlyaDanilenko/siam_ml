{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "frame_test = pd.read_csv(\"hq_markup_train.csv\")\n",
    "frame_test.fillna(-2, inplace=True)\n",
    "# frame_test[\"Граница постоянного давления_details\"] = np.log10(frame_test[\"Граница постоянного давления_details\"])\n",
    "# frame_test[\"Граница непроницаемый разлом_details\"] = np.log10(frame_test[\"Граница непроницаемый разлом_details\"])\n",
    "# frame_test.fillna(-0.5, inplace=True)\n",
    "frame = pd.read_csv(\"markup_train.csv\")\n",
    "frame.fillna(-2, inplace=True)\n",
    "\n",
    "def get_sample(index, frame):\n",
    "    uuid = frame.iloc[index, 0]\n",
    "    with open(f'data/{uuid}', 'r') as f:\n",
    "        content = f.read()\n",
    "    rows = [line.split('\\t') for line in content.strip().split('\\n')]\n",
    "    data = pd.DataFrame(rows, columns=['time', 'delta_p', 'p_'], dtype=float)\n",
    "    return data\n",
    "\n",
    "\n",
    "def find_empty_indexes_2(data):\n",
    "    \"\"\"\n",
    "    Поиск id файлов из строк датафрейма для их исключения на этапе удаления данных из датафрейма\n",
    "    \"\"\"\n",
    "    B=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        try:\n",
    "            df=get_sample(i,data)\n",
    "        except ValueError:\n",
    "            B.append(data.iloc[i,0])\n",
    "    return B\n",
    "\n",
    "\n",
    "# class SiamDataset(Dataset):\n",
    "#     def __init__(self, siam_dataset_describe:pd.DataFrame):\n",
    "#         super().__init__()\n",
    "#         self.siam_dataset_describe = siam_dataset_describe\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.siam_dataset_describe.shape[0]\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = get_sample(idx, self.siam_dataset_describe) #.to_numpy(dtype=np.float64)\n",
    "#         # t = x[\"time\"].to_numpy(dtype=np.float64)\n",
    "#         x = x[[\"delta_p\", \"p_\"]].to_numpy(dtype=np.float64)\n",
    "        \n",
    "\n",
    "\n",
    "#         # 7) Возвращаем (X, Y)                                                  # Давление(атм) ([:, 1]) Давление(атм) ([:,1]) Давление(атм) ([:,1]) Давление(атм) ([:,1]) Давление(атм) ([:,1]) В какой момент? [:, 0]   В какой момент? [:, 0]\n",
    "#         return x, self.siam_dataset_describe.iloc[idx][['Влияние ствола скважины_details', 'Радиальный режим_details', 'Линейный режим_details', 'Билинейный режим_details', 'Сферический режим_details', 'Граница постоянного давления_details', 'Граница непроницаемый разлом_details']].to_numpy(dtype=np.float32)\n",
    "\n",
    "B=find_empty_indexes_2(frame)#Поиск id с отсутствующими файлами для исключения\n",
    "frame=frame[~frame['file_name'].isin(B)]#Фильтрация данных\n",
    "frame = frame[~frame[\"file_name\"].isin(frame_test[\"file_name\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Классическое позиционное кодирование (NLP-стиль).\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=4000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() \n",
    "                             * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe / (d_model ** 0.5)\n",
    "        pe = pe.unsqueeze(0)    # [1, max_len, d_model]\n",
    "        self.register_buffer('pe', pe) \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x shape: [B, T, d_model]\n",
    "        Добавляем позиционное кодирование к x.\n",
    "        \"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        x = x + self.pe[:, :seq_len, :]\n",
    "        # print(f\"Encoded x: {x}\")\n",
    "        return x\n",
    "\n",
    "class TransformerFlowModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Пример трансформера для задач:\n",
    "      - 8 бинарных признаков (классификация)\n",
    "      - 7 регрессионных выходов\n",
    "    С учётом attention mask (padding).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_dim=3,     # (delta_p, p_, log_time) например\n",
    "                 d_model=64,\n",
    "                 nhead=4,\n",
    "                 num_layers=2,\n",
    "                 dim_feedforward=128,\n",
    "                 dropout=0.1,\n",
    "                 n_class=8,\n",
    "                 n_reg=5):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        # self.pos_encoder = PositionalEncoding(d_model)\n",
    "        torch.nn.init.xavier_uniform_(self.input_proj.weight, gain=1.0)\n",
    "        torch.nn.init.zeros_(self.input_proj.bias)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model,\n",
    "                                                   nhead=nhead,\n",
    "                                                   dim_feedforward=dim_feedforward,\n",
    "                                                   dropout=dropout,\n",
    "                                                   activation=\"relu\",\n",
    "                                                   batch_first=True)  \n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)  # mean-pool по временной оси\n",
    "\n",
    "        self.class_head = nn.Linear(d_model, n_class)\n",
    "        self.reg_head   = nn.Linear(d_model, n_reg)\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        x: [B, T, input_dim]\n",
    "        src_key_padding_mask: [B, T], True = игнорируем (паддинг)\n",
    "        \"\"\"\n",
    "        # 1) Линейная проекция входа -> d_model\n",
    "        x_proj = self.input_proj(x)  # [B, T, d_model]\n",
    "        if torch.isnan(x_proj).any():\n",
    "            print(\"NaN after input projection\")\n",
    "        # 2) Позиционное кодирование\n",
    "        # x_encoded = self.pos_encoder(x_proj)  # [B, T, d_model]\n",
    "        # if torch.isnan(x_encoded).any():\n",
    "            # print(\"NaN after positional encoding\")\n",
    "        # 3) Пропускаем через энкодер\n",
    "        #    Важно: указываем mask=... (или src_key_padding_mask=...).\n",
    "        #    Маска должна быть типа bool, shape [B, T]\n",
    "        x_trans = self.transformer_encoder(\n",
    "            # x_encoded,\n",
    "            x_proj,\n",
    "            src_key_padding_mask=src_key_padding_mask\n",
    "        )  # [B, T, d_model]\n",
    "        if torch.isnan(x_trans).any():\n",
    "            print(\"NaN after transformer\")\n",
    "\n",
    "        # 4) Pooling, [B, d_model]\n",
    "        x_trans_perm = x_trans.permute(0, 2, 1)  # -> [B, d_model, T]\n",
    "        pooled = self.pool(x_trans_perm).squeeze(-1)  # [B, d_model]\n",
    "        if torch.isnan(pooled).any():\n",
    "            print(\"NaN after pooling\")\n",
    "\n",
    "        # 5) Выход\n",
    "        class_logits = self.class_head(pooled)  # [B, 8]\n",
    "        reg_output   = self.reg_head(pooled)    # [B, 7]\n",
    "        if torch.isnan(pooled).any():\n",
    "            print(\"NaN after class_logits\")\n",
    "        return class_logits, reg_output\n",
    "\n",
    "\n",
    "class ConvTransformer(nn.Module):\n",
    "    def __init__(self, d_model=32, nhead=2, num_layers=1, dim_feedforward = 128, in_channels = 2):\n",
    "        super().__init__()\n",
    "        # 1) Conv1d: in_channels=2 (delta_p, p_), out_channels=d_model\n",
    "        #    kernel_size=3 -> можно менять\n",
    "        self.conv = nn.Conv1d(in_channels=in_channels, out_channels=d_model, kernel_size=31, padding=15, groups=in_channels)\n",
    "        self.in_channels = in_channels\n",
    "        # 2) TransformerEncoder (упрощённый)    \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=0.0,\n",
    "            activation='relu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # 3) Heads для классификации (8) и регрессии (7)\n",
    "        # self.class_head = nn.Linear(d_model, 8)\n",
    "        self.reg_preload   = nn.Linear(d_model, 64)\n",
    "        self.reg_activate = nn.LeakyReLU(0.3)\n",
    "        self.reg_head   = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        x: [B, T, 2]\n",
    "        src_key_padding_mask: [B, T] (bool), True=игнорировать позицию\n",
    "        \"\"\"\n",
    "        # -- (A) Свёртка --\n",
    "        # Conv1d ожидает [B, C, T], значит permute:\n",
    "        x = x.permute(0, 2, 1)  # -> [B, 2, T]\n",
    "\n",
    "        # Прогон через conv:\n",
    "        # Выход будет [B, d_model, T]\n",
    "        x_conv = self.conv(x)  # [B, d_model, T]\n",
    "\n",
    "        # -- (B) Для Transformer делаем [B, T, d_model]\n",
    "        x_conv = x_conv.permute(0, 2, 1)  # [B, T, d_model]\n",
    "\n",
    "        # -- (C) Прогон через TransformerEncoder, с учётом mask\n",
    "        x_trans = self.transformer_encoder(\n",
    "            x_conv,\n",
    "            src_key_padding_mask=src_key_padding_mask\n",
    "        )  # [B, T, d_model]\n",
    "\n",
    "        # -- (D) Возьмём, например, средний вектор по времени\n",
    "        x_pooled = x_trans.mean(dim=1)  # [B, d_model]\n",
    "\n",
    "        # -- (E) Предсказываем 8 бинарных признаков + 7 регрессий\n",
    "        # class_logits = self.class_head(x_pooled)  # [B, 8]\n",
    "        reg_out      = self.reg_head(self.reg_activate(self.reg_preload(x_pooled)))    # [B, 7]\n",
    "        return reg_out\n",
    "        # return class_logits, reg_out\n",
    "\n",
    "\n",
    "\n",
    "class SiamDataset(Dataset):\n",
    "    def __init__(self, siam_dataset_describe:pd.DataFrame):\n",
    "        super().__init__()\n",
    "        self.siam_dataset_describe = siam_dataset_describe\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.siam_dataset_describe.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = get_sample(idx, self.siam_dataset_describe)\n",
    "        # x = torch.from_numpy(get_sample(idx, self.siam_dataset_describe).to_numpy(dtype=np.float32)) #.to_numpy(dtype=np.float64)\n",
    "        # t = x[\"time\"].to_numpy(dtype=np.float64)\n",
    "        def calculate_log_pressure(pressure):\n",
    "            \"\"\"Calculate log of pressure for log-log plots\"\"\"\n",
    "            # Ensure all pressure values are positive\n",
    "            min_positive = np.min(pressure[pressure > 0]) / 10 if any(pressure > 0) else 1e-10\n",
    "            adjusted_pressure = np.maximum(pressure, min_positive)\n",
    "            return np.log10(adjusted_pressure)\n",
    "        \n",
    "        x[\"time\"] = np.log10(x[\"time\"])\n",
    "        x[\"delta_p\"] = calculate_log_pressure(x[\"delta_p\"])\n",
    "        x[\"p_\"] = calculate_log_pressure(x[\"p_\"]) \n",
    "                         # \"time\",   \"delta_p\",\n",
    "        x =  torch.from_numpy(x[[\"time\", \"delta_p\", \"p_\"]].to_numpy(dtype=np.float32))\n",
    "        \n",
    "        # x =  torch.from_numpy(x[[\"p_\"]].to_numpy(dtype=np.float32))\n",
    "        if torch.isnan(x).any():\n",
    "            # print(get_sample(idx, self.siam_dataset_describe))\n",
    "            mask = ~torch.isnan(x).any(dim=1)\n",
    "            x = x[~mask]\n",
    "\n",
    "            \n",
    "            # print(x)\n",
    "            # raise Exception(\"ахтунг в данных\")\n",
    "        if x.shape[0] == 0:\n",
    "            x = torch.tensor([0,0,0])\n",
    "\n",
    "\n",
    "        # 7) Возвращаем (X, Y)                                                                                                                                              # не работает если ставить 1 число\n",
    "        return x, torch.from_numpy(self.siam_dataset_describe.iloc[idx][self.siam_dataset_describe.columns[3:11]].to_numpy(dtype=np.float32)), torch.from_numpy(self.siam_dataset_describe.iloc[idx][self.siam_dataset_describe.columns[11:]].to_numpy(dtype=np.float32))\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn_with_padding(batch):\n",
    "    \"\"\"\n",
    "    batch: список из (X, y_class, y_reg), где X shape [T_i, input_dim].\n",
    "    Нужно вернуть:\n",
    "      padded_X: [B, max_len, input_dim]\n",
    "      src_key_padding_mask: [B, max_len] (bool)\n",
    "      y_class: [B, 8]\n",
    "      y_reg:   [B, 7]\n",
    "    \"\"\"\n",
    "    # 1) Определяем batch_size\n",
    "    batch_size = len(batch)\n",
    "    # 2) Находим максимальную длину среди X\n",
    "    lengths = [sample[0].shape[0] for sample in batch]  # T_i для каждого\n",
    "    max_len = max(lengths)\n",
    "    input_dim = batch[0][0].shape[1]\n",
    "\n",
    "    # 3) Создаём тензоры под результирующие данные\n",
    "    padded_X = torch.zeros((batch_size, max_len, input_dim), dtype=torch.float)\n",
    "    # Маска: True = игнорируем => паддинг\n",
    "    # Изначально False (значит реальная точка), затем выставим True там, где нет реальных данных\n",
    "    src_key_padding_mask = torch.zeros((batch_size, max_len), dtype=torch.bool)\n",
    "\n",
    "    y_class_list = []\n",
    "    y_reg_list = []\n",
    "\n",
    "    # 4) Копируем данные в паддинг-тензоры\n",
    "    for i, (X, y_class, y_reg) in enumerate(batch):\n",
    "        length = X.shape[0]\n",
    "        padded_X[i, :length, :] = X\n",
    "        # Для элементов после length делаем mask = True\n",
    "        if length < max_len:\n",
    "            src_key_padding_mask[i, length:] = True\n",
    "\n",
    "        y_class_list.append(y_class)\n",
    "        y_reg_list.append(y_reg)\n",
    "\n",
    "    # 5) Склеиваем метки\n",
    "    y_class_tensor = torch.stack(y_class_list, dim=0)  # [B, 8]\n",
    "    y_reg_tensor   = torch.stack(y_reg_list, dim=0)   # [B, 7]\n",
    "\n",
    "    return padded_X, src_key_padding_mask, y_class_tensor, y_reg_tensor\n",
    "\n",
    "def train():\n",
    "    # Создаём датасет\n",
    "    dataset = SiamDataset(frame_test)\n",
    "    # Создаём DataLoader\n",
    "    loader = DataLoader(dataset, \n",
    "                        batch_size=8, \n",
    "                        shuffle=True, \n",
    "                        collate_fn=collate_fn_with_padding)\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device is {device}\")\n",
    "    # device = 'cpu'\n",
    "\n",
    "    # model = ConvTransformer(d_model=96, nhead=16, num_layers=4, dim_feedforward=128, in_channels=1)\n",
    "    model = ConvTransformer(d_model=60, nhead=10, num_layers=3, dim_feedforward=256, in_channels=3)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "    bce_loss = nn.BCEWithLogitsLoss()\n",
    "    mse_loss = nn.L1Loss(reduction=\"mean\")\n",
    "    model.train()\n",
    "    for epoch in range(25):\n",
    "        total_loss = 0.0\n",
    "        for batch_data in loader:\n",
    "            # batch_data = (padded_X, src_key_padding_mask, y_class, y_reg)\n",
    "            padded_X, src_mask, y_class, y_reg = batch_data\n",
    "            # print(padded_X)\n",
    "            padded_X = padded_X.to(device)\n",
    "            src_mask = src_mask.to(device)\n",
    "            # y_class  = y_class.to(device)\n",
    "            # print(y_reg)\n",
    "            y_reg = y_reg[:, 0].view(-1, 1)\n",
    "\n",
    "            # print(y_reg)\n",
    "            y_reg = y_reg.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Прогон через модель\n",
    "            # logits, reg_out = model(padded_X, src_key_padding_mask=src_mask)\n",
    "            reg_out = model(padded_X, src_key_padding_mask=src_mask)\n",
    "            # print(reg_out)\n",
    "            # print(y_reg)\n",
    "\n",
    "            # Лосс по классификации\n",
    "            # loss_class = bce_loss(logits, y_class)\n",
    "            # Лосс по регрессии\n",
    "            loss_reg = mse_loss(reg_out, y_reg)\n",
    "            # l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "\n",
    "            loss =  loss_reg  #+ l1_norm #+  loss_reg\n",
    "            # print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, loss={total_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=404.8748\n",
      "Epoch 2, loss=412.4134\n",
      "Epoch 3, loss=381.7196\n",
      "Epoch 4, loss=396.7958\n",
      "Epoch 5, loss=363.1393\n",
      "Epoch 6, loss=363.7514\n",
      "Epoch 7, loss=375.0607\n",
      "Epoch 8, loss=416.9490\n",
      "Epoch 9, loss=388.2826\n",
      "Epoch 10, loss=341.3006\n"
     ]
    }
   ],
   "source": [
    "# model.train()\n",
    "# for epoch in range(10):\n",
    "#     total_loss = 0.0\n",
    "#     for batch_data in loader:\n",
    "#         # batch_data = (padded_X, src_key_padding_mask, y_class, y_reg)\n",
    "#         padded_X, src_mask, y_class, y_reg = batch_data\n",
    "\n",
    "#         padded_X = padded_X.to(device)\n",
    "#         src_mask = src_mask.to(device)\n",
    "#         # y_class  = y_class.to(device)\n",
    "#         y_reg    = y_reg.to(device)\n",
    "#         y_reg = y_reg[:, 0].view(-1, 1)\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Прогон через модель\n",
    "#         # logits, reg_out = model(padded_X, src_key_padding_mask=src_mask)\n",
    "#         # print(logits)\n",
    "#         # print(y_class)\n",
    "#         reg_out = model(padded_X, src_key_padding_mask=src_mask)\n",
    "#         # Лосс по классификации\n",
    "#         # loss_class = bce_loss(logits, y_class)\n",
    "#         # Лосс по регрессии\n",
    "#         loss_reg = mse_loss(reg_out, y_reg)\n",
    "#         l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "\n",
    "#         loss = loss_reg   #+ l1_norm #+ loss_reg loss_class\n",
    "#         # print(loss)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "#     print(f\"Epoch {epoch+1}, loss={total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python3\\Lib\\site-packages\\torch\\cuda\\memory.py:391: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "d:\\Python3\\Lib\\site-packages\\torch\\cuda\\memory.py:417: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "torch.cuda.reset_max_memory_allocated()  # Сброс максимального использования памяти\n",
    "torch.cuda.reset_max_memory_cached()     # Сброс кэшированной памяти\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# Очистка кэша CUDA\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rinning at cuda\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# # device = \"cpu\"\n",
    "# # model.to(device=device)\n",
    "# print(f\"rinning at {device}\")\n",
    "# # dataset = SiamDataset(frame_test)\n",
    "# loader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_with_padding)\n",
    "# all_proba = []\n",
    "# all_real_y = []\n",
    "# all_reg = []\n",
    "# all_y_reg = []\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for padded_X, src_mask, y_class, y_reg in loader:\n",
    "\n",
    "#         padded_X = padded_X.to(device)\n",
    "#         src_mask = src_mask.to(device)\n",
    "#         # y_class  = y_class.to(device)\n",
    "#         y_reg = y_reg.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Прогон через модель\n",
    "#         # logits, reg_out = model(padded_X, src_key_padding_mask=src_mask)\n",
    "#         reg_out = model(padded_X, src_key_padding_mask=src_mask)\n",
    "#         # print(logits)\n",
    "#         # print(y_class)\n",
    "\n",
    "#         # Лосс по классификации\n",
    "#         # loss_class = bce_loss(logits, y_class)\n",
    "#         all_reg.append(reg_out.cpu())\n",
    "#         all_y_reg.append(y_reg.cpu())\n",
    "        \n",
    "#         pred_proba = torch.sigmoid(reg_out)\n",
    "#         all_proba.append(pred_proba.cpu())\n",
    "#         all_real_y.append(y_class.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n",
      "[array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(0., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32), array(1., dtype=float32)]\n",
      "[array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32), array([0], dtype=int32), array([1], dtype=int32), array([1], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# all_real_y_2 = [tensor[0, 1].cpu().detach().numpy() for tensor in all_real_y]\n",
    "# pred_proba_2 = [tensor.cpu().detach().numpy() for tensor in all_proba]\n",
    "# all_answers_2 = [(pred_proba[0] > 0.5).int().cpu().detach().numpy() for pred_proba in all_proba]\n",
    "# # # all_answers_2 = \n",
    "# print(len(all_real_y_2))\n",
    "# print(len(all_answers_2))\n",
    "# print(all_real_y_2)\n",
    "# print(all_answers_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[185], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_reg_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtmp_reg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m tmp_reg \u001b[38;5;129;01min\u001b[39;00m all_reg])[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m all_y_reg_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([tmp_reg[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m tmp_reg \u001b[38;5;129;01min\u001b[39;00m all_y_reg])[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# np.mean(np.abs(np.array(all_y_reg_2) - np.array(all_reg_2)), axis=0)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "# all_reg_2 = np.array([tmp_reg[0].cpu().detach().numpy() for tmp_reg in all_reg])[:, 0]\n",
    "# all_y_reg_2 = np.array([tmp_reg[0].cpu().detach().numpy() for tmp_reg in all_y_reg])[:, 0]\n",
    "\n",
    "# # np.mean(np.abs(np.array(all_y_reg_2) - np.array(all_reg_2)), axis=0)\n",
    "# mask = all_y_reg_2 > 0\n",
    "# all_reg_2[mask] = 0\n",
    "# all_y_reg_2[mask] = 0\n",
    "# # all_reg_2\n",
    "# # all_y_reg_2\n",
    "# np.mean(np.abs(np.array(all_y_reg_2) - np.array(all_reg_2)), axis=0)\n",
    "# # np.abs(np.array(all_y_reg_2) - np.array(all_reg_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Precision: 0.8338316095669037, Recall: 0.8237155001860884, F1: 0.8284938779771226, Hamming Loss: 0.138\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss\n",
    "# precision = precision_score(all_real_y_2, all_answers_2, average='macro')\n",
    "\n",
    "# recall = recall_score(all_real_y_2, all_answers_2, average='macro')\n",
    "\n",
    "# f1 = f1_score(all_real_y_2, all_answers_2, average='macro')\n",
    "\n",
    "# hamming = hamming_loss(all_real_y_2, all_answers_2)\n",
    "# print(np.sum(np.all(np.array(all_answers_2) == np.array(all_real_y_2), axis=1))/len(all_answers_2))\n",
    "# print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}, Hamming Loss: {hamming}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка\n",
    "def eval_model(reg_models:list[nn.Module], class_real_index:int):\n",
    "    dataset = SiamDataset(frame_test)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_with_padding)\n",
    "    for model in reg_models:\n",
    "        model.eval()\n",
    "\n",
    "    all_mae = [[] for _ in range(n_class)]\n",
    "    all_real_y = []\n",
    "    all_reg = [[] for _ in range(n_class)]\n",
    "    all_y_reg = []\n",
    "    all_proba = [[] for _ in range(n_class)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in loader:\n",
    "            padded_X, src_mask, y_class, y_reg = batch_data\n",
    "            padded_X = padded_X.to(device)\n",
    "            src_mask = src_mask.to(device)\n",
    "            # y_class = y_class[:, 1:n_class + 1].to(device)\n",
    "            y_reg = y_reg.to(device)\n",
    "\n",
    "            # Предсказание классов\n",
    "            # logits = classifier(padded_X, src_key_padding_mask=src_mask)\n",
    "            # y_class_pred = (logits > 0).float()  # Бинарные предсказания\n",
    "\n",
    "            # all_y_class_true.append(y_class.cpu())\n",
    "            # all_y_class_pred.append(y_class_pred.cpu())\n",
    "\n",
    "            # Оценка регрессии для каждого класса\n",
    "            for i in range(n_class):\n",
    "                # mask = y_class[:, i] == 1\n",
    "                # if mask.any():\n",
    "                    # padded_X_i = padded_X[mask]\n",
    "                    # src_mask_i = src_mask[mask]\n",
    "                    # y_reg_i = y_reg[mask, i]\n",
    "\n",
    "                reg_out = reg_models[i](padded_X, src_key_padding_mask=src_mask).squeeze(-1)\n",
    "                # mask = y_reg_i > 0\n",
    "                # print(mask)\n",
    "                mae = torch.abs(reg_out - y_reg[:, i + class_real_index].view(-1, 1)).mean().item()\n",
    "                all_mae[i].append(mae)\n",
    "                all_reg[i].append(reg_out.cpu().detach().numpy())\n",
    "                \n",
    "                \n",
    "                pred_proba = torch.sigmoid(reg_out)\n",
    "                all_proba.append(pred_proba.cpu().detach().numpy())\n",
    "            all_y_reg.append(y_reg.cpu().detach().numpy())    \n",
    "            all_real_y.append(y_class.cpu().detach().numpy())\n",
    "\n",
    "    # Вычисление метрик\n",
    "    # Средний MAE по классам\n",
    "    mae_per_class = [np.mean(maes) if maes else 0 for maes in all_mae]\n",
    "\n",
    "    # Точность классификации (доля правильно предсказанных меток)\n",
    "    # all_y_class_true = torch.cat(all_y_class_true, dim=0)\n",
    "    # all_y_class_pred = torch.cat(all_y_class_pred, dim=0)\n",
    "    # accuracy = (all_y_class_true == all_y_class_pred).float().mean().item()\n",
    "\n",
    "    # Вывод результатов\n",
    "    # print(f\"Точность предсказания классов: {accuracy:.4f}\")\n",
    "    for i in range(n_class):\n",
    "        print(f\"MAE для класса {i}: {mae_per_class[i]:.4f}\")\n",
    "\n",
    "    # print(len([i[0] for i in all_reg[0]]))\n",
    "    for class_index in range(n_class):\n",
    "    # class_index = 6\n",
    "    # print(all_real_y)\n",
    "        all_reg_2 = np.array([i[0] for i in all_reg[class_index]])\n",
    "        all_y_reg_2 = np.array([i[0, class_index] for i in all_y_reg])\n",
    "        # print(all_y_reg_2)\n",
    "        # all_reg_2 = all_reg_2[:, 0]\n",
    "\n",
    "        # np.mean(np.abs(np.array(all_y_reg_2) - np.array(all_reg_2)), axis=0)\n",
    "        mask = all_y_reg_2 > 0\n",
    "        all_reg_2[mask] = 0\n",
    "        all_y_reg_2[mask] = 0\n",
    "        # all_reg_2\n",
    "        # all_y_reg_2\n",
    "        print(f\"class index {class_real_index} MAE:\", np.mean(np.abs(np.array(all_y_reg_2) - np.array(all_reg_2)), axis=0))\n",
    "        print(f\"class index {class_real_index} Совпадения с MAE < 0.15:\", np.sum((np.abs(np.array(all_y_reg_2) - np.array(all_reg_2))) <= 0.15) / len(dataset))\n",
    "        # np.abs(np.array(all_y_reg_2) - np.array(all_reg_2))\n",
    "\n",
    "    import os\n",
    "    # Папка для сохранения моделей\n",
    "    save_dir = \"saved_models\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Сохраняем каждую модель\n",
    "    for idx, model in enumerate(reg_models):\n",
    "        # Сохраняем состояние модели\n",
    "        model_path = os.path.join(save_dir, f\"BESTTransmodelv2_{class_real_index}class_P_and_derivative{idx}.pt\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Модель для класса {idx} сохранена в {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python3\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "d:\\Python3\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "d:\\Python3\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Устройство\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device is {device}\")\n",
    "\n",
    "# Создаем датасет и загрузчик (предполагается, что frame_test определен)\n",
    "\n",
    "# Параметры\n",
    "n_class = 1  # Используем обучение по 1 из 7 классов\n",
    "n_epochs = 6\n",
    "\n",
    "for class_index in range(5):\n",
    "    dataset = SiamDataset(frame)\n",
    "    loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn_with_padding)\n",
    "\n",
    "    class_index = 0\n",
    "\n",
    "    \n",
    "\n",
    "    # Инициализация моделей\n",
    "    # classifier = ClassConvTransformer(in_channels=3, n_class=n_class).to(device)\n",
    "    reg_models = [ConvTransformer(d_model=60, nhead=10, num_layers=2, dim_feedforward=128, in_channels=3).to(device) for _ in range(n_class)]\n",
    "\n",
    "    # Оптимизаторы\n",
    "    # optimizer_class = optim.Adam(classifier.parameters(), lr=3e-4)\n",
    "    optimizers_reg = [optim.Adam(model.parameters(), lr=3e-4) for model in reg_models]\n",
    "\n",
    "    # Функции потерь\n",
    "    # bce_loss = nn.BCEWithLogitsLoss()\n",
    "    mse_loss = nn.L1Loss(reduction=\"mean\")\n",
    "\n",
    "    # Обучение\n",
    "    for epoch in range(n_epochs):\n",
    "        for model in reg_models:\n",
    "            model.train()\n",
    "        \n",
    "        total_loss_class = 0.0\n",
    "        total_loss_reg = [0.0] * n_class\n",
    "        \n",
    "        for batch_data in loader:\n",
    "            padded_X, src_mask, y_class, y_reg = batch_data\n",
    "            padded_X = padded_X.to(device)\n",
    "            src_mask = src_mask.to(device)\n",
    "            # y_class = y_class[:, :n_class].to(device)  # Берем первые 7 меток\n",
    "            # y_reg = y_reg.to(device)                   # [B, 7]\n",
    "\n",
    "            # # Обучение классификатора\n",
    "            # optimizer_class.zero_grad()\n",
    "            # logits = classifier(padded_X, src_key_padding_mask=src_mask)\n",
    "            # loss_class = bce_loss(logits, y_class)\n",
    "            # loss_class.backward()\n",
    "            # optimizer_class.step()\n",
    "            # total_loss_class += loss_class.item()\n",
    "\n",
    "            # Обучение регрессионных моделей\n",
    "            for i in range(n_class):\n",
    "                y_reg = y_reg[:,i + class_index].view(-1, 1).to(device)\n",
    "                # mask = y_class[:, i+1] == 1  # Образцы, где класс i активен\n",
    "                # print(i)\n",
    "                # if mask.any():\n",
    "                # padded_X_i = padded_X[mask]\n",
    "                # # src_mask_i = src_mask[mask]\n",
    "                # y_reg_i = y_reg[mask, i].view(-1, 1)\n",
    "\n",
    "                optimizers_reg[i].zero_grad()\n",
    "                reg_out = reg_models[i](padded_X, src_key_padding_mask=src_mask)\n",
    "                loss_reg = mse_loss(reg_out, y_reg)\n",
    "                loss_reg.backward()\n",
    "                optimizers_reg[i].step()\n",
    "                total_loss_reg[i] += loss_reg.item()\n",
    "                del padded_X, src_mask, y_reg, reg_out\n",
    "                torch.cuda.empty_cache()  # Освобождение кэша CUDA\n",
    "\n",
    "        # Вывод логов\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        for i in range(n_class):\n",
    "            if total_loss_reg[i] > 0:\n",
    "                print(f\"    Class {i + class_index} Regression Loss = {total_loss_reg[i]:.4f}\")\n",
    "\n",
    "\n",
    "    eval_model(reg_models, class_real_index=class_index)\n",
    "    del reg_models[0]\n",
    "    torch.cuda.empty_cache()  # Освобождение кэша CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class index 0 MAE: 0.7075205\n",
      "0.726\n"
     ]
    }
   ],
   "source": [
    "# print(len([i[0] for i in all_reg[0]]))\n",
    "for class_index in range(n_class):\n",
    "# class_index = 6\n",
    "# print(all_real_y)\n",
    "    all_reg_2 = np.array([i[0] for i in all_reg[class_index]])\n",
    "    all_y_reg_2 = np.array([i[0, class_index] for i in all_y_reg])\n",
    "    # print(all_y_reg_2)\n",
    "    # all_reg_2 = all_reg_2[:, 0]\n",
    "\n",
    "    # np.mean(np.abs(np.array(all_y_reg_2) - np.array(all_reg_2)), axis=0)\n",
    "    mask = all_y_reg_2 > 0\n",
    "    all_reg_2[mask] = 0\n",
    "    all_y_reg_2[mask] = 0\n",
    "    # all_reg_2\n",
    "    # all_y_reg_2\n",
    "    print(f\"class index {class_index} MAE:\", np.mean(np.abs(np.array(all_y_reg_2) - np.array(all_reg_2)), axis=0))\n",
    "    print(np.sum((np.abs(np.array(all_y_reg_2) - np.array(all_reg_2))) <= 0.15) / len(dataset))\n",
    "    # np.abs(np.array(all_y_reg_2) - np.array(all_reg_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель для класса 0 сохранена в saved_models\\BESTmodelv1_0classONLYderivative0.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Папка для сохранения моделей\n",
    "save_dir = \"saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Сохраняем каждую модель\n",
    "for idx, model in enumerate(reg_models):\n",
    "    # Сохраняем состояние модели\n",
    "    model_path = os.path.join(save_dir, f\"BESTmodelv1_1classONLYderivative{idx}.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Модель для класса {idx} сохранена в {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_real_y_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score, hamming_loss\n\u001b[1;32m----> 2\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(\u001b[43mall_real_y_2\u001b[49m, all_answers_2, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(all_real_y_2, all_answers_2, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(all_real_y_2, all_answers_2, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_real_y_2' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss\n",
    "precision = precision_score(all_real_y_2, all_answers_2, average='macro')\n",
    "\n",
    "recall = recall_score(all_real_y_2, all_answers_2, average='macro')\n",
    "\n",
    "f1 = f1_score(all_real_y_2, all_answers_2, average='macro')\n",
    "\n",
    "hamming = hamming_loss(all_real_y_2, all_answers_2)\n",
    "print(np.sum(np.all(np.array(all_answers_2) == np.array(all_real_y_2), axis=1))/len(all_answers_2))\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}, Hamming Loss: {hamming}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float32' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_real_y_2 \u001b[38;5;241m=\u001b[39m [\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m all_real_y]\n\u001b[0;32m      2\u001b[0m pred_proba_2 \u001b[38;5;241m=\u001b[39m [tensor\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m all_proba]\n\u001b[0;32m      3\u001b[0m all_answers_2 \u001b[38;5;241m=\u001b[39m [(pred_proba[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m pred_proba \u001b[38;5;129;01min\u001b[39;00m all_proba]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float32' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "\n",
    "all_real_y_2 = [tensor[0, 1].cpu().detach().numpy() for tensor in all_real_y]\n",
    "pred_proba_2 = [tensor.cpu().detach().numpy() for tensor in all_proba]\n",
    "all_answers_2 = [(pred_proba[0] > 0.5).int().cpu().detach().numpy() for pred_proba in all_proba]\n",
    "# # all_answers_2 = \n",
    "print(len(all_real_y_2))\n",
    "print(len(all_answers_2))\n",
    "print(all_real_y_2)\n",
    "print(all_answers_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
